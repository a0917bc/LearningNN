{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd00e444486c269546cbe63895cad067211537eba99a77df67394b2a8e68340f12f",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pooling(image, pooling_size, W_O, H_O):\n",
    "    index = np.zeros((W_O, H_O))\n",
    "    output = np.zeros((W_O, H_O))\n",
    "    for y in range(0, image.shape[1], pooling_size):\n",
    "        for x in range(0, image.shape[0], pooling_size):\n",
    "            index[x//2, y//2] = np.argmax(image[x:x+pooling_size, y:y+pooling_size])\n",
    "            output[x//2, y//2] = (image[x:x+pooling_size, y:y+pooling_size]).max()\n",
    "    return output, index\n",
    "\n",
    "\n",
    "# def pooling(image, pooling_size, W_O, H_O, I):\n",
    "\n",
    "#     output = np.zeros((W_O, H_O))\n",
    "#     for y in range(0, image.shape[1], pooling_size):\n",
    "#         for x in range(0, image.shape[0], pooling_size):\n",
    "#             output[x//2, y//2] = (image[x:x+pooling_size,\n",
    "#                                   y:y+pooling_size]).mean()\n",
    "#     return output\n",
    "\n",
    "\n",
    "def poolingLayer(input_feature_map, pooling_size=2):   \n",
    "    # Check whether it's 3D or not.\n",
    "    W_O = input_feature_map.shape[1]//2\n",
    "    H_O = input_feature_map.shape[2]//2\n",
    "    C_I = input_feature_map.shape[0]\n",
    "    output_feature_map = np.zeros((C_I, W_O, H_O))\n",
    "    for cin in range(C_I):\n",
    "        output_feature_map[cin] = pooling(input_feature_map[cin], pooling_size, W_O, H_O)\n",
    "    return output_feature_map\n",
    "\n",
    "\n",
    "# A = np.random.randint(0, 16, (3, 4, 4))\n",
    "# poolingLayer(A, 3, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline, already solved by VS code\n",
    "np.set_printoptions(precision = 2)\n",
    "class MLP(object):\n",
    "    '''Multi_Layer Perceptron, Fully-Connected Layer'''\n",
    "    \n",
    "    def __init__(self, Layers = (2, 2, 3), BatchSize = 4):\n",
    "        self.bs = BatchSize\n",
    "        self.lr = float()\n",
    "        self.LeakyRate = float()\n",
    "        self.act = str()\n",
    "        self.net = [dict() for _ in range(len(Layers))]# Every element in the list is a dictionary \n",
    "\n",
    "        self.net[0]['a'] = np.zeros((Layers[0], self.bs), dtype = 'float16')\n",
    "        self.net[0]['dJda'] = np.zeros(self.net[0]['a'].shape, dtype = 'float16')\n",
    "        \n",
    "        for i in range(1, len(Layers)):\n",
    "            self.net[i]['a'] = np.zeros((Layers[i], self.bs), dtype = 'float16')\n",
    "            self.net[i]['z'] = np.zeros(self.net[i]['a'].shape, dtype = 'float16')\n",
    "            self.net[i]['W'] = np.random.randn(Layers[i], Layers[i - 1]).astype('float16')\n",
    "            self.net[i]['b'] = np.random.randn(Layers[i], 1).astype('float16')\n",
    "            self.net[i]['dJda'] = np.zeros(self.net[i]['a'].shape, dtype = 'float16')\n",
    "            self.net[i]['dJdz'] = np.zeros(self.net[i]['z'].shape, dtype = 'float16')\n",
    "            self.net[i]['dJdW'] = np.zeros(self.net[i]['W'].shape, dtype = 'float16')\n",
    "            self.net[i]['dJdb'] = np.zeros(self.net[i]['b'].shape, dtype = 'float16')\n",
    "        \n",
    "        self.p = np.zeros(self.net[-1]['a'].shape, dtype = 'float16') # Softmax Out\n",
    "        self.dJdp = np.zeros(self.p.shape, dtype='float16')\n",
    "\n",
    "        self.yhat = np.zeros(self.bs, dtype=int) # Predicted Answer\n",
    "        self.yhat_onehot = np.zeros(self.p.shape, dtype=int)\n",
    "        self.y_onehot = np.zeros(self.p.shape, dtype=int)\n",
    "\n",
    "        self.J = []\n",
    "        self.W_trace = []\n",
    "\n",
    "\n",
    "    def softmax(self, a):\n",
    "        delta = 1.0\n",
    "        return np.exp(a + delta) / np.sum(np.exp(a + delta), axis=0)\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0 / (1.0 + np.exp(-1.0 * z))\n",
    "    def sigmoidPrime(self, a): # sigmoid's derivative\n",
    "        return a * (1.0 -a)\n",
    "    def ReLU(self, z):\n",
    "        a = np.copy(z)\n",
    "        a[a < 0] = 0.0\n",
    "        return a\n",
    "    def ReLUPrime(self, a):\n",
    "        dadz = np.copy(a)\n",
    "        dadz[a > 0] = 1.0\n",
    "        return dadz\n",
    "    def activation(self, z):\n",
    "        a = np.copy(z)\n",
    "        if self.act == \"sigmoid\":\n",
    "            a = self.sigmoid(z)\n",
    "        #elif self.act == \"ReLU\":\n",
    "        #    a = self.LeakyReLU\n",
    "        else:\n",
    "            print(\"Activation Selection Error\")\n",
    "        return a\n",
    "    def activationPrime(self, a):\n",
    "        if self.act == \"sigmoid\":\n",
    "            z = self.sigmoidPrime(a)\n",
    "        else:\n",
    "            print(\"Activation Selection Error\")\n",
    "        return z\n",
    "    # Warren\n",
    "    def forward(self, x): # \"copyto\" looks like directly manipulate the value at some address\n",
    "        np.copyto(self.net[0]['a'], x) # Copy input into a of Layer 0\n",
    "\n",
    "        for i in range(1, len(self.net)): # Start from 0; Let i start from 1\n",
    "            np.copyto(self.net[i]['z'], np.dot(self.net[i]['W'], self.net[i-1]['a']) + self.net[i]['b']) # iterator\n",
    "            np.copyto(self.net[i]['a'], self.activation(self.net[i]['z']))\n",
    "        \n",
    "        np.copyto(self.p, self.softmax(self.net[-1]['a']))\n",
    "        np.copyto(self.yhat, np.argmax(self.p, axis=0))# Final predicated answer\n",
    "        return\n",
    "\n",
    "    def loss(self, y):\n",
    "        '''only a \"1\" '''\n",
    "        self.y_onehot.fill(0)\n",
    "        for i in range(self.bs):\n",
    "            self.y_onehot[y[i], i] = 1 # Compare & Turn on\n",
    "        loss_value = -1.0 * np.sum(self.y_onehot * np.log(self.p)) / self.bs\n",
    "\n",
    "        self.J.append(loss_value) # Look \n",
    "# fffff\n",
    "        W = []\n",
    "        for i in range(1, len(self.net)):\n",
    "            W.extend(np.ravel(self.net[i]['W'])) # ravel =? extend\n",
    "            W.extend(np.ravel(self.net[i]['b']))\n",
    "        self.W_trace.append(W)\n",
    "        return\n",
    "\n",
    "    def backprop(self):\n",
    "        self.dJdp = 1.0 / (1.0 - self.y_onehot - self.p)\n",
    "\n",
    "        dpda = np.array([[self.p[i, :] * (1.0 - self.p[j, :]) if i == j\n",
    "                          else -1 * self.p[i, :] * self.p[j, :]\n",
    "                          for i in range(self.p.shape[0])]\n",
    "                          for j in range(self.p.shape[0])])\n",
    "        for i in range(self.bs):\n",
    "            self.net[-1]['dJda'][:, i] = np.dot(dpda[:, :, i], self.dJdp[:, i])\n",
    "\n",
    "        for i in range((len(self.net) - 1), 0, -1):# computed function \n",
    "            np.copyto(self.net[i]['dJdz'], (self.net[i]['dJda'] * self.activationPrime(self.net[i]['a'])))\n",
    "\n",
    "            np.copyto(self.net[i]['dJdb'], np.mean(self.net[i]['dJdz'], axis = 1)[:, None])\n",
    "\n",
    "            np.copyto(self.net[i]['dJdW'], np.dot(self.net[i]['dJdz'], self.net[i-1]['a'].T) / self.bs)\n",
    "\n",
    "            np.copyto(self.net[i - 1]['dJda'], np.dot((self.net[i]['W']).T, self.net[i]['dJdz']))\n",
    "        return\n",
    "\n",
    "    def update(self):\n",
    "        for i in range(1, len(self.net)):\n",
    "            np.copyto(self.net[i]['W'], self.net[i]['W'] - self.lr * self.net[i]['dJdW']) # += may work\n",
    "            #self.net[i]['W'] -= self.lr * self.net[i]['dJdW']\n",
    "            np.copyto(self.net[i]['b'], self.net[i]['b'] - self.lr * self.net[i]['dJdb'])\n",
    "        return\n",
    "    \n",
    "    def train(self, train_x, train_y, epoch_count = 1000, lr = 0.01, act = \"sigmoid\", LeakyRate = 0.1):\n",
    "        self.lr = lr\n",
    "        self.act = act\n",
    "        self.LeakyRate = LeakyRate\n",
    "\n",
    "        for _ in range(epoch_count): # constant times for, solved:how to eliminate warning the variable isn't used \n",
    "            for i in range(train_x.shape[1] // self.bs): \n",
    "                x = train_x[:, i * self.bs : (i + 1) * self.bs]\n",
    "                y = train_y[i * self.bs : (i + 1) * self.bs]\n",
    "                self.forward(x)\n",
    "                self.loss(y)\n",
    "                self.backprop()\n",
    "                self.update()\n",
    "        return\n",
    "\n",
    "    def inference(self, inference_x):\n",
    "        yhat = []\n",
    "        for i in range(inference_x.shape[1]//self.bs):\n",
    "            x = inference_x[:, i * self.bs:(i + 1) * self.bs]\n",
    "            self.forward(x)\n",
    "            yhat.extend(list(self.yhat))\n",
    "        return yhat\n",
    "    \n",
    "    def plot_W(self):\n",
    "        curve = [[] for i in range(len(self.W_trace[0]))]\n",
    "        for j in range(len(self.W_trace[0])):\n",
    "            for i in range(len(self.W_trace)):\n",
    "                curve[j].append(self.W_trace[i][j])\n",
    "        for c in curve:\n",
    "                plt.plot(c)\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d4d776b6ee4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindecies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "z, indecies = pooling(A[0], 2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}